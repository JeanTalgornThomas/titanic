{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\benpr\\Documents\\IPSSI\\titanic\\titanic\\notebook.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/benpr/Documents/IPSSI/titanic/titanic/notebook.ipynb#ch0000001?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconf\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkConf\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/benpr/Documents/IPSSI/titanic/titanic/notebook.ipynb#ch0000001?line=2'>3</a>\u001b[0m config \u001b[39m=\u001b[39m SparkConf()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/benpr/Documents/IPSSI/titanic/titanic/notebook.ipynb#ch0000001?line=3'>4</a>\u001b[0m spark \u001b[39m=\u001b[39m SparkSession\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mmaster(\u001b[39m\"\u001b[39;49m\u001b[39mlocal\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mappName(\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mconfig(conf\u001b[39m=\u001b[39;49mconfig)\u001b[39m.\u001b[39;49mgetOrCreate()\n",
      "File \u001b[1;32mc:\\Users\\benpr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\sql\\session.py:186\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/sql/session.py?line=183'>184</a>\u001b[0m         sparkConf\u001b[39m.\u001b[39mset(key, value)\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/sql/session.py?line=184'>185</a>\u001b[0m     \u001b[39m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/sql/session.py?line=185'>186</a>\u001b[0m     sc \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39;49mgetOrCreate(sparkConf)\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/sql/session.py?line=186'>187</a>\u001b[0m \u001b[39m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/sql/session.py?line=187'>188</a>\u001b[0m \u001b[39m# by all sessions.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/sql/session.py?line=188'>189</a>\u001b[0m session \u001b[39m=\u001b[39m SparkSession(sc)\n",
      "File \u001b[1;32mc:\\Users\\benpr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\context.py:378\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=375'>376</a>\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=376'>377</a>\u001b[0m     \u001b[39mif\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=377'>378</a>\u001b[0m         SparkContext(conf\u001b[39m=\u001b[39;49mconf \u001b[39mor\u001b[39;49;00m SparkConf())\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=378'>379</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32mc:\\Users\\benpr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\context.py:133\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=127'>128</a>\u001b[0m \u001b[39mif\u001b[39;00m gateway \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m gateway\u001b[39m.\u001b[39mgateway_parameters\u001b[39m.\u001b[39mauth_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=128'>129</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=129'>130</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=130'>131</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is not allowed as it is a security risk.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=132'>133</a>\u001b[0m SparkContext\u001b[39m.\u001b[39;49m_ensure_initialized(\u001b[39mself\u001b[39;49m, gateway\u001b[39m=\u001b[39;49mgateway, conf\u001b[39m=\u001b[39;49mconf)\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=133'>134</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=134'>135</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=135'>136</a>\u001b[0m                   conf, jsc, profiler_cls)\n",
      "File \u001b[1;32mc:\\Users\\benpr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\context.py:327\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=324'>325</a>\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=325'>326</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_gateway:\n\u001b[1;32m--> <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=326'>327</a>\u001b[0m         SparkContext\u001b[39m.\u001b[39m_gateway \u001b[39m=\u001b[39m gateway \u001b[39mor\u001b[39;00m launch_gateway(conf)\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=327'>328</a>\u001b[0m         SparkContext\u001b[39m.\u001b[39m_jvm \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_gateway\u001b[39m.\u001b[39mjvm\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/context.py?line=329'>330</a>\u001b[0m     \u001b[39mif\u001b[39;00m instance:\n",
      "File \u001b[1;32mc:\\Users\\benpr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\java_gateway.py:105\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/java_gateway.py?line=101'>102</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.1\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/java_gateway.py?line=103'>104</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/java_gateway.py?line=104'>105</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJava gateway process exited before sending its port number\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/java_gateway.py?line=106'>107</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(conn_info_file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m info:\n\u001b[0;32m    <a href='file:///c%3A/Users/benpr/AppData/Local/Programs/Python/Python39/lib/site-packages/pyspark/java_gateway.py?line=107'>108</a>\u001b[0m     gateway_port \u001b[39m=\u001b[39m read_int(info)\n",
      "\u001b[1;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "config = SparkConf()\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"test\").config(conf=config).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Builder' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\benpr\\Documents\\IPSSI\\titanic\\titanic\\notebook.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/benpr/Documents/IPSSI/titanic/titanic/notebook.ipynb#ch0000000?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m sc\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39mheader\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39minferSchema\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mcsv(\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mrain.csv\u001b[39m\u001b[39m\"\u001b[39m) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/benpr/Documents/IPSSI/titanic/titanic/notebook.ipynb#ch0000000?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39mprintSchema()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Builder' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "df = sc.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"data\\train.csv\") \n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f4e994e616bc70104392ad43172e29317900d3f313f6865515deae64a667d82"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
